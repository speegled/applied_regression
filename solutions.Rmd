# Solutions

## Chapter 2 Solutions

**Exercise 2.1**

a. We have that $\overline{X}$ is normal with mean $\overline{\mu}$ and variance $\frac 1{25}\sum \sigma_i^2$, i.e. $\overline{X} \sim N(3, \sigma^2 = 2.2)$. 

b. To confirm this via simulations:

```{r}
sim_data <- replicate(10000, {
  x <- rnorm(5, 1:5, sqrt((1:5)^2))
  mean(x)
})
mean(sim_data) #cf 3
var(sim_data) #cf 2.2
```

```{r}
plot(density(sim_data))
curve(dnorm(x, 3, sqrt(2.2)), add = T, col = 2)
```

**Exercise 2.2**
```{r}
bp.obese <- ISwR::bp.obese
sse <- function(beta) {
  sum((bp.obese$bp - (beta[1] + beta[2] * bp.obese$obese))^2)
}

optim(par = c(0,0), fn = sse)
```

Our line of best fit is $y = 96.8 + 23 x$.  Confirm with `lm`:

```{r}
lm(bp ~ obese, data = bp.obese)
```

For part (b), either answer is OK. The data seems pretty good to me, but I can see where some people didn't think so. As long as you say why.

**Exercise 2.3**

a. Note that $\sum_{i = 1}^n \beta_0 = n\beta_0$. The solution is $\hat \beta_0 = \overline{y} - \overline{x}$.

b. $\hat \beta_0$ is normal with mean $\beta_0$ and variance $\sigma^2/n$.

c. Let's simulate.

```{r}
xs <- runif(20, 0, 10)
sim_data <- replicate(10000, {
  ys <- 2 + xs + rnorm(20, 0, 1)  
  mean(ys) - mean(xs)
})
plot(density(sim_data))
curve(dnorm(x, 2, 1/sqrt(20)), add = T, col = 2)
```

**Exercise 2.4**

We have that 
\[
\frac{\hat \beta_1 - \beta_1}{\sqrt{nS^2/(n\sum x_i^2 - (\sum x_i)^2)}} \sim t_{n -2}
\]
So we compute.

```{r}
dd <- HistData::Galton
mod <- lm(child ~ parent, data = dd)
summary(mod)
```

The estimate for $S$ is given as 2.239, which we use. We compute the test statistic:

```{r}
(0.64629 - 1)/sqrt(2.239^2/(sum(dd$parent^2) - 1/928 * sum(dd$parent)^2))
```
The test statistic is -8.596837. We need to compute the likelihood of obtaining something that unlikely given that $H_0$ is true.


```{r}
pt(-8.596837, 926) * 2
```

With this $p$-value, we reject the null hypothesis. We conlcude that the slope is not 1. With more work, we can see that this means (roughly) that parents who are short or tall will tend to have children that are again short or tall, but less so than the parents.  Does that mean that eventually there will be little variation among heights of humans. Why or why not?

**Exercise 2.5**

a. An unbiased estimator for $S^2$ is 
\[
\frac{1}{n-1} \sum_{ i = 1}^n \bigl(y_i - \hat\beta_0 - x_i\bigr)^2
\]

b. Standard normal.

c. $t$ with $n-1$ degrees of freedom.

d. 
```{r, eval=FALSE}
dd <- read.csv("https://stat.slu.edu/~speegle/Spring2020/4870/data/problem_2_5.csv")
```

```{r, echo=FALSE}
dd <- read.csv("data/problem_2_5.csv")
```


```{r}
beta_0 <- mean(dd$ys) - mean(dd$xs)
s <- sqrt(1/(nrow(dd) - 1) * sum((dd$ys - beta_0 - dd$xs)^2))
test_stat <- (beta_0 - 2)/(s/sqrt(nrow(dd)))
test_stat
pt(test_stat, nrow(dd) - 1, lower.tail = FALSE) * 2
```

Note that this is the same as a paired $t$-test, where we have as our null hypothesis that $y_i - x_i$ is normal with mean 2 and unknown standard deviation. 

```{r}
t.test(dd$ys, dd$xs, mu = 2, paired = T)
```

**Exercise 2.6**

a. 
```{r}
dd <- carData::Davis
plot(dd$repwt, dd$weight)
```

b.
```{r}
mod_lm <- lm(weight ~ repwt, data = dd)
mod_huber <- MASS::rlm(weight ~ repwt, data = dd, psi = MASS::psi.huber)
mod_tukey <- MASS::rlm(weight ~ repwt, data = dd, psi = MASS::psi.bisquare)
plot(dd$repwt, dd$weight)
abline(mod_lm, col = 2) #red
abline(mod_huber, col = 3) #green
abline(mod_tukey, col = 4) #blue
```


## Chapter 3 Solutions

1. Let's load the data.

```{r}
secher <- ISwR::secher
plot(secher[,-4])
mod <- lm(bwt ~ bpd + ad, data = secher)
summary(mod)
```
Looks like a pretty good model already. Let's check the diagnostics.

```{r}
plot(mod)
```

Could be some skewness there. Let's see if a transformation might help the normality of the residuals.

```{r}
MASS::boxcox(mod)
```

This suggests a log transform of the response would improve the normality of the residuals. Finally, let's put `no` back in to the model. We hope that it is not strongly significant, as that might be an indicator of some sort of experimental flaw.

```{r}
mod2 <- lm(bwt ~., data = secher)
summary(mod2)
```
Note that `no` is not significant, and the Adjusted R-squared decreased. Both of these are what we would like to see.

## Chapter 5

3. Let's load the data.

```{r}
set.seed(2252020)
library(AppliedPredictiveModeling)
data("ChemicalManufacturingProcess")
```

The problem asks us to do an initial test/train split and work with the train data from there on out. I'll pull out the test data and leave the train data with the same variable name.

```{r}
test_indices <- sample(1:176, 46)
test_dat <- ChemicalManufacturingProcess[test_indices,]
ChemicalManufacturingProcess <- ChemicalManufacturingProcess[-test_indices,]
```


The data isn't in the format that the book said it would be in. Let's create a matrix of predictors and a vector response, in addition to the data frame with both.

```{r}
predictors <- ChemicalManufacturingProcess[,-1]
response <- ChemicalManufacturingProcess[,1]
```

Now let's see about missing data.

```{r}
sum(is.na(predictors))
```

We do have missing data, so we will need to preprocess. The first part of the problem asks us to do Principle Component Regression. Let's do it using the `caret` package.

```{r}
library(caret)
train(x = predictors, 
      y = response, 
      method = "pcr", 
      preProcess = c("center", "scale", "medianImpute", "nzv"))
```

I think we need to expand our tune grid a bit.

```{r}
tuneGrid <- data.frame(ncomp = 1:20)
pca_mod <- train(x = predictors, 
      y = response, 
      method = "pcr", 
      tuneGrid = tuneGrid,
      preProcess = c("center", "scale", "medianImpute", "nzv"))
apply(pca_mod$results[,c(2, 5)], 1, sum)
```

The smallest value 1 se away from the estimated MSE is `r min(apply(pca_mod$results[,c(2, 5)], 1, sum))`. So, by our one se rule of them, we will choose

```{r}
ncomp <- which(pca_mod$results[,2] < min(apply(pca_mod$results[,c(2, 5)], 1, sum)))
ncomp <- min(ncomp)
ncomp
```

This says that we need one component, and our estimate for the MSE is roughly $2.1 \pm  .92$.

```{r}
pca_mod$results[1,2]
pca_mod$results[1,5]
```

Let's check it out on our test set that we haven't touched yet. We first have to apply the same pre-processing steps to the test data as we did to the train data.

```{r}
preprocess_mod <- preProcess(predictors, 
                             method = c("scale", "center", "medianImpute", "nzv"))
test_predictors <- test_dat[,-1]
test_response <- test_dat[,1]
test_processed <- predict(preprocess_mod, newdata = test_predictors)
```

Now we can predict the outcomes on the test set.

```{r}
predict(pca_mod$finalModel, newdata = test_processed, ncomp = 1)[,,1]
errors <- predict(pca_mod$finalModel, newdata = test_processed, ncomp = 1)[,,1] - test_response
mean(errors^2)
```

This value is within 2 se of the predicted value based on CV. 

